SW프로젝트 요약서
프로젝트 기간	2018.xx.xx. - 2018.xx.xx. (총00개월) (반드시 요약서와 보고서 기간와 개월수가 일치해야함)
2021.08.25 - 2021.05.24

프로젝트 팀원	이름(학과, 학년), 이사자(컴퓨터소프트웨어학부, 4학년)
한재은(컴퓨터소프트웨어학부, 4학년)
양소진(컴퓨터소프트웨어학부, 4학년)

지도교수	지도교수님 성함 기입
박영준

프로젝트 멘토 	산업체 멘토님 성함 기입 (반드시 멘토님 회사명 기입하세요.)
김경호 (S-OIL CISO조직)

프로젝트 명	프로젝트 명 기입(반드시 보고서와 일치해야 함)
머신러닝 어플리케이션 가속을 위한 FPGA가속기 최적화

프로젝트 내용	
아래 내용을 자유롭게 기술
- 프로젝트의 이름
- 프로젝트의 목적
- 프로젝트의 수행 내용
- 프로젝트의 결과
본 프로젝트에서는 TVM과 VTA를 사용한다. TVM은 CPU,GPU 그리고 하드웨어 가속기를 위한 머신러닝 컴파일러 프레임워크이다. VTA는 TVM의 확장으로 프로그래밍 가능한 하드웨어 가속기이다. 본 프로젝트의
목표는 VTA의 구조를 개선하여 TVM을 통해 실행되는 머신러닝 어플리케이션의 성능을 향상시키는 것이다.
본 프로젝트의 수행 단계는 TVM 및 VTA의 구조와 동작방식 파악, VTA 개선점 탐구, VTA 구조 개선이다. 먼저, TVM과 VTA의 구조를 파악하기 위하여 관련 논문을 통해 이론적인 내용을 학습하였다. 그리고 VTA 튜토리얼을 따라서 실습을 진행하며 TVM과 VTA의 동작 방식을 학습하였다. 다음으로, 관련 논문 및 공식 문서를 참고하여 VTA의 파이프라인은 개선점으로 정하였다. 마지막으로 VTA 코드 분석 및 수정을 거치면서 VTA의 구조를 개선하였다.

기대효과 및 개선방향	- 학술적, 산업적 응용분야와 기대효과를 기술
최근 다양한 분야에서 머신 러닝을 활용하기 위해 노력하고 있다. 이를 위해 NPU등 새로운 형태의 하드웨어가 제안되기도 하였다. 이러한 배경 속에서 머신러닝을 위한 설계 가능한 가속기인 VTA를 개선하는 프로젝트를 수행함으로써 다양한 분야에서 머신러닝을 위해 사용할 하드웨어 가속기의 구조를 설계하는데 긍정적인 효과를 줄 것을 기대한다. 

프로젝트
요약	프로젝트 목표, 내용, 결과 (200자 내외)
본 프로젝트의 목표는 VTA의 구조를 개선하여 TVM을 통해 실행되는 머신러닝 어플리케이션의 성능을 향상시키는 것이다. 본 프로젝트에서는 VTA operation step의 불균형을 문제점으로 제기하였다. 이를 해결하기 위해 VTA의 compute 모듈을 분리하는 작업을 실시하였고 operation step이 전과 비교하여 균등하게 나뉜 결과를 확인할 수 있었다.

산학프로젝트의 기술적 내용
  - SW 및 HW 개발환경 소개
  - 적용기술에 대한 소개 및 적용 방법
  - 어려웠던 점과 그 해결과정 등 기술
  본 프로젝트를 진행함에 있어 주로 사용한 언어는 c++과 python이고, git을 사용하여 버전을 관리하였다. 설계한 VTA를 실험하기 위해 FPGA 보드인 pynq Z1 보드를 사용하였다.
본 프로젝트에서는 compute 모듈의 operation step을 줄이기 위해 compute 모듈 안에 있는 ALU를 compute 모듈에서 분리하기로 결정하였다. 
compute 모듈을 분리하는 과정에서 가장 어려운 점은 dependency 처리였다. VTA는 모듈들을 병렬로 동작하게 하여 성능 향상 효과를 얻는다. 하지만, 병렬로 동작함에 따라 모듈들이 공통으로 필요로 하는 데이터에 대해 RAW, WAR dependency가 생긴다. 이를 해결하기 위해 VTA는 dependence FIFO queue를 사용한다. compute 모듈에서 ALU를 분리함에 따라 dependency queue 구조도 바꿔야 했다.
새로운 dependency queue 구조를 설계하기 위해 compute 모듈과 ALU 모듈 사이의 관계를 파악해야 했다. 이를 위해, 시뮬레이션을 통해 VTA 튜토리얼의 명령어를 분석하였다. 그 결과, compute 모듈 안에서 처리하는 gemm 연산 후에 무조건 alu 연산을 거치고 store로 넘어간다는 것을 확인했다. 따라서, compute와 alu사이, alu와 store사이에 dependency queue를 넣어주는 구조로 설계하였다. 

5. 결론 및 기대효과
프로젝트를 시작하면서 TVM과 VTA에 대해 공부할 때는 내용이 너무 어렵고 개선점을 찾는 것도 막막해서 주제를 잘못 골랐다고 생각했다. 하지만, 멘토님께서 장기 프로젝트를 진행할 때는 기간별 목표를 정해서 진행하는 것이 시간관리에 좋다고 말씀해주셨고, 멘토님의 말씀대로 목표를 세분화하여 데드라인을 정하고, 그것을 지켜나가며 진행하니 원하는 바에 점점 다다를 수 있었다. 장기 프로젝트를 진행할 때는 기간 별 목표 수립을 통한 진행이 중요하다는 것을 체감했다.
본 프로젝트의 최종 목표는 머신 러닝을 위한 하드웨어 가속기인 VTA의 성능을 향상하는 것이었다. 본 프로젝트의 기대 효과는 다음과 같다.
최근 다양한 분야에서 머신 러닝을 활용하기 위해 노력하고 있다. 그에 따라 머신 러닝의 성능을 더 높이기 위해 NPU와 같은 머신 러닝에 특화된 하드웨어 개발도 활발하게 이루어지고 있다. 이러한 배경 속에서 머신 러닝을 위한 설계 가능한 가속기인 VTA를 개선하는 프로젝트를 수행함으로써 다양한 분야에서 머신 러닝을 위해 사용할 하드웨어 가속기의 구조를 설계하는데 긍정적인 효과를 줄 것을 기대한다.
해결하지 못한 과제는 두 가지가 있다. 먼저, compute 모듈과 alu 모듈 사이 acc 메모리 공유 문제를 해결해야 한다. 이를 해결하기 위해서는 gemm연산이 끝나는 시점과 alu 연산이 시작하는 시점을 알아채고 그 시점에 acc 버퍼를 사용하여 두 모듈 사이에서 acc 데이터를 손실 없이 이동시켜야 한다. 두 번째는 TVM의 명령어 생성방법 수정을 통한 VTA 명령어 수정 및 이를 통한 구조 검증이다. 이를 해결하기 위해서는 TVM에서 VTA 스케줄을 생성하는 부분에서 dependency를 주입하는 부분을 찾고 이를 수정해야 한다. 

